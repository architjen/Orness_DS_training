{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"toc_visible":true,"mount_file_id":"1S_9SjwQugbDy1HdPlVd_vvuNeZaFszJd","authorship_tag":"ABX9TyOBRXJhRh/YfE/T7QPEGNJw"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["#Machine Learning\n","-> Ability for computers to learn something without being explicitly programmed -- Andrew NG   \n","eg: Classfying an email as a spam or not"],"metadata":{"id":"mQ5Rk44pvc1K"}},{"cell_type":"markdown","source":["## Why do we need ML?  \n","\n","While some tasks cant be software engineered, the others cant be. For eg: finding a shortest path could be performed by DSA algorithms, but classfying between a car image and a bike image ? Or pen and a pencil ?  \n","\n","Machine Learning algorithms learn to differentiate just like humans do, by making mistakes and correcting them later - or more precisely ```learning from the past experiences```\n"],"metadata":{"id":"8ZpcdIG2JztZ"}},{"cell_type":"markdown","source":["## Types of ML algorithms  \n","\n","```Supervised``` - We have the labels while training the data. \n","eg: Dog vs Cat classifier, wine quality, Fraud detection etc\n","\n","```Unsupervised``` - We dont have the labels, infact we dont even know have the target defined. \n","eg: Number of tee shirts (S,M,L), Number of iPhones launch ?  \n","\n","```Reinforcement``` - Algorithms best on the reward scenarios eg: Balancing Stick, juggling football, etc"],"metadata":{"id":"qtos3uhYLmJy"}},{"cell_type":"markdown","source":["Supervised learning can be used to solve two types of problems: ```Classification``` and ```Regression```  \n","\n","![class_reg_image](https://drive.google.com/uc?id=13jSXFri2f8hWZYbqGpV5lA6XDcqsvoEC)"],"metadata":{"id":"0BDS9W-NSVkq"}},{"cell_type":"markdown","source":["## Mathematics behind ML"],"metadata":{"id":"DXoM3KKVsWxz"}},{"cell_type":"markdown","source":["lets try to understand what happens mathematically in ML:  \n","\n","\n","lets say you have an equation of line ```y = 2x + 3```\n","\n","given x point [1,2,3,4,5] you'll get the **y as [5,7,9,11,13]**"],"metadata":{"id":"jcz_Lgk7UEBx"}},{"cell_type":"markdown","source":["Now in ML what happens is generally we have the data points --   \n","```[x,y] = [(1,5), (2,7), (3,9), (4,11), (5,13)]```\n","\n","*NOTE: x could be a feature (column) and y a label*\n","\n","and we have to formulate the equation of a line "],"metadata":{"id":"8USWkXjnVbaY"}},{"cell_type":"markdown","source":["# Model Training"],"metadata":{"id":"DMXWckb-xFQF"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"o6YhS5Eethf7"},"outputs":[],"source":["import os\n","import pandas as pd \n","\n","# numerical calculation library\n","import numpy as np\n","\n","# Viz libraries\n","import matplotlib.pyplot as plt\n","import seaborn as sns\n","\n","#Machine learning libraries\n","# sklearn remains one of the most imp library for beginner Machine Learning \n","from sklearn.model_selection import train_test_split\n","from sklearn.linear_model import LogisticRegression \n","from sklearn.neighbors import KNeighborsClassifier\n","\n","# calculating performance\n","from sklearn.metrics import accuracy_score, mean_squared_error"]},{"cell_type":"markdown","source":["```scikit-learn``` remains one of the most imp library for Machine Learning. You could perform almost all the traiditional ML algorithms using the library, all you'd need is some data.   \n","Please refer to the beginner-friendly blog on [scikit-learn](https://jakevdp.github.io/PythonDataScienceHandbook/05.02-introducing-scikit-learn.html)  \n","\n","You could also refer to the official doc [here](https://scikit-learn.org/stable/)"],"metadata":{"id":"m5-785KELX3F"}},{"cell_type":"markdown","source":["## Data construction"],"metadata":{"id":"q0NKSQQ8xQXW"}},{"cell_type":"code","source":["path = \"/content/drive/MyDrive/Colab_Notebooks/orness/clean_data/\""],"metadata":{"id":"70rGd8kUuRmS"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["df = pd.read_csv(path+\"winequality.csv\")"],"metadata":{"id":"1dIpN-GRuSkF"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["df.head()"],"metadata":{"id":"IQYRnKsA2235"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["df.info()"],"metadata":{"id":"BSxQZWegQVW6"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Converting the problem into ```binary classification```"],"metadata":{"id":"gYLiMIM-bR6O"}},{"cell_type":"code","source":["Y = df['TARGET'].apply(lambda y: 1 if y > 5 else 0)"],"metadata":{"id":"krs3MZ4muYqA"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Why apply ?"],"metadata":{"id":"dO-M2xT66__f"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["X = df.drop('TARGET', axis=1)"],"metadata":{"id":"nnCDe4ogvyCN"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["X.shape, Y.shape"],"metadata":{"id":"o24xHtbZv7CL"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["X"],"metadata":{"id":"77Kl46E6Ne_u"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Data Split"],"metadata":{"id":"e6_vRf6qxYjK"}},{"cell_type":"markdown","source":["We need to split our data into ```train set``` and ```test set```.  \n","\n","So we build our ML model using the train data and then check its performance on the test data."],"metadata":{"id":"gjT5BSoKYwDJ"}},{"cell_type":"code","source":["x_train, x_test, y_train, y_test = train_test_split(X, Y, test_size=0.25,random_state=42)"],"metadata":{"id":"LaT3rFt_v-kh"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["x_train.shape, x_test.shape, y_train.shape, y_test.shape "],"metadata":{"id":"1xAjqc45NAPu"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Model Training 1. Logistic Regression"],"metadata":{"id":"0VganEllxcb0"}},{"cell_type":"markdown","source":["We'll use logistic regression algorithm to model our data  \n","\n","![log_reg](https://drive.google.com/uc?id=1yqtkIOzHt5RYc-pgR4Q8MB60hBY86DPa)"],"metadata":{"id":"qj6jskffaqoI"}},{"cell_type":"code","source":["LR = LogisticRegression() # solver\n","LR.fit(x_train, y_train)"],"metadata":{"id":"1Oupqub-NMv0"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["If you want more info on Logistic Regression please check out the [scikit learn page](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html)  \n","For mathematical aspect of it along with the code, please follow [here](https://www.analyticsvidhya.com/blog/2021/07/an-introduction-to-logistic-regression/)"],"metadata":{"id":"cIDcE11DbBNJ"}},{"cell_type":"code","source":["# Predict the x_test data on our model \n","y_pred = LR.predict(x_test)"],"metadata":{"id":"4P270vJ7N6t7"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["accuracy_score(y_test, y_pred)"],"metadata":{"id":"Mud9lgoWOMRL"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Model Training 2. K-Nearest Neigbor"],"metadata":{"id":"RDtPMjz1xmQ2"}},{"cell_type":"markdown","source":["Lets try running a K-NN algorithm and see the performance"],"metadata":{"id":"p9WffHnVoLts"}},{"cell_type":"code","source":["KNN = KNeighborsClassifier()\n","KNN.fit(x_train, y_train)"],"metadata":{"id":"m97KkV1nO25_"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Lets see what exactly KNN is trying to do here  \n","\n","![knn](https://drive.google.com/uc?id=1S5UvP-cGM1E1AlvjqPvJJn_48tf3hon6)"],"metadata":{"id":"lU_fc1gLphto"}},{"cell_type":"code","source":["y_pred_knn = KNN.predict(x_test)"],"metadata":{"id":"xaFIoQTsR00k"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["accuracy_score(y_test, y_pred_knn)"],"metadata":{"id":"0RVLceCYSASp"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Manual test data"],"metadata":{"id":"fuYPXLOQxx75"}},{"cell_type":"markdown","source":["We passed a negative integer for the other dimension. That means the remaining dimension becomes whatever shape is needed to make it hold all the original data"],"metadata":{"id":"cKXybBMDo-7x"}},{"cell_type":"code","source":["# test on any row of the column to see the correctness \n","input = np.asarray(df.drop('TARGET', axis=1).iloc[2]).reshape(1, -1)\n","LR.predict(input)"],"metadata":{"id":"4R-wWqQySL7C"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Please refer the [Data Sci book](https://jakevdp.github.io/PythonDataScienceHandbook/) here to further hone your skills.  \n","Data Sci Github - https://github.com/khuyentran1401/Data-science  \n","Data Sci resources - https://github.com/tirthajyoti/Data-science-best-resources   \n","ml blog - https://machinelearningmastery.com/start-here/#getstarted  \n","Practise numpy and pandas [here](https://github.com/tirthajyoti/Machine-Learning-with-Python/blob/master/Pandas%20and%20Numpy/Pandas_Operations.ipynb)"],"metadata":{"id":"BToFk1QGwYJ6"}},{"cell_type":"markdown","source":["## Model pickling (dumping)"],"metadata":{"id":"brzSbF2Ax5z2"}},{"cell_type":"markdown","source":["Model Pickling is an important step once your model is trained. So that our model (which is simply a matrix of weights) could be further used to make the prediction. Furtheron this matrix could be served in the front end UI to make the predictions. \n","\n"],"metadata":{"id":"c-dZUapmyK-0"}},{"cell_type":"code","source":["#library to dump the python objects into binary  \n","import pickle"],"metadata":{"id":"yXTDf9a2wY7Y"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["with open('model_pkl', 'wb') as files:\n","    pickle.dump(LR, files)"],"metadata":{"id":"JpE_LMAktfjm"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["ls"],"metadata":{"id":"k7nkEhKev8PV"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["with open('model_pkl' , 'rb') as f:\n","    lr = pickle.load(f)"],"metadata":{"id":"gesgoljlv9G3"},"execution_count":null,"outputs":[]}]}